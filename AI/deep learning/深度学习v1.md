[toc]



# 1 引入

Machine Learning(ML): acquiring **skill** with experience accumulated/computed from **data**

```mermaid
graph LR
    A("data") --> B("ML")
    B --> C("skill")
    style A stroke-dasharray: 5 5
    style B stroke:#333,stroke-width:3px
    style C stroke-dasharray: 5 5
```

> [!note]
>
> common application
>
> 1. speech recognition
> 2. image recognition
> 3. playing go
>



机器学习分类：

1. supervised learning
2. Semi-supervised learning
3. unsupervised learning



> [!tip]
>
> 在机器学习或深度学习中的单词缩写：
>
> - SOTA(state of the art): 最先进的

## 1.1 self-supervised learning

self-supervised learning：自监督学习，预先进行一些训练（pre-train），然后再来处理数据

:telescope:例如：下图会将图片进行反转和调色，然后让模型自行判断图片中主体是否是同一个，通过预训练，我们可以让模型先打好 "基本功"，然后再对数据集进行处理，从开发通用目标知识（develop general purpose knowledge）

<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240922154406252.png" alt="image-20240922154406252" style="zoom: 67%;" />

当学习这些 "基本功" 后，该模型处理下游任务（downstream tasks）就比较好处理

<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240922155839143.png" alt="image-20240922155839143" style="zoom:50%;" />



pre-trained model 和 downstream tasks 的关系类似于操作系统和应用之间的关系，下游任务只需要在 pre-trained model 上进行实现，而不需要关心底层的交互逻辑，因此 pre-trained model 又被称为 ==foundation model==

> [!note]
>
> 在 foundation model 中，最为人所熟知的便是 ==BERT==



## 1.2 Generative Adversarial Network

生成对抗网络（Generative Adversarial Networks， GANs）：Gan 主要是由 ==生成器（Generator）== 和==判别器（Discriminator）== 组成，其中生成器不断优化自己生产的数据让判别器判断不出来，判别器也要优化自己让自己判别地更加准确，两者形成对抗关系。

<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240922163822583.png" alt="image-20240922163822583" style="zoom:50%;" />

推荐论文

| 方向                                   | 论文                                                         |
| -------------------------------------- | ------------------------------------------------------------ |
| Unsupervised Abstractive Summarization | https://arxiv.org/abs/1810.02851                             |
| Unsupervised Translation               | https://arxiv.org/abs/1710.04087<br />https://arxiv.org/abs/1710.11041 |
| Unsupervised ASR                       | https://arxiv.org/abs/1804.00316<br />https://arxiv.org/abs/1812.09323<br />https://arxiv.org/abs/1904.04100<br />https://arxiv.org/abs/2105.11084 |



## 1.3 Reinforcement Learning

application scenarios: *it is challenging to label data in some tasks*.

> [!tip]
>
> when we can't know the results are good or not, use **RL**

 

## 1.4 Advanced Topic

1. Anomaly Detection
2. Explainable AI 
3. Model Attack
4. Domain Adaptation 
5. Network Compression
6. Life-long Learning
7. Meta learning



# 2 机器学习基本概念   

**different types of functions** 

- **Regression**: The function outputs a scalar.

  > [!tip]
  >
  > example: predict PM2.5

- **Classification**: Given options(classes), the function outputs the correct one.

  > [!tip]
  >
  > example: spam filtering

- **Structured Learning**: Create something with structure(image, document)



机器学习建模的基本流程

1. find a **function** with unknown parameters, e.g. $y=wx+b$

   > [!tip]
   >
   > Here, function == model

2. define **loss** from training data, $L(b, w)$

   <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923101459616.png" alt="image-20240923101459616" style="zoom:50%;" />

3. optimization: $w^*, b^*=arg\ \mathop{min}\limits_{w, b} L$

   Gradient Descent:

   - (randomly) pick a initial value $w^0$, $b^0$

   - compute $\begin{equation}\frac{\partial L}{\partial w}|_{w=w^0}\end{equation}$, $\begin{equation}w^1\leftarrow w^0-\eta\frac{\partial L}{\partial w}|_{w=w^0}\end{equation}$, $\begin{equation}b^{1}\leftarrow b^{0}-\eta\frac{\partial L}{\partial b}|_{{w=w^{0},b=b^{0}}}\end{equation}$

     <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923101716562.png" alt="image-20240923101716562" style="zoom:50%;" />

   - update $w$ iteratively

   > [!warning]
   >
   > 1. 在梯度下降的过程中，$step=\eta\frac{\partial L}{\partial w}$，其中 $\eta$ 为 learning rate, $\frac{\partial L}{\partial w}$ 为任意点在某处的微分，当达到 minima 点时（==local minima== or ==global minima==），$\frac{\partial L}{\partial w}=0$，移动将会停下
   > 2. 我们都知道损失函数无论是使用 L1-norm 还是 L2-norm, 计算的结果都是大于等于 0 的，为什么在这里图中显示的 Loss 可以小于 0， 原因是 Loss 函数只是用到了 L1-norm 或 L2-norm，但是具体的函数表达式可能增加了惩罚项，例如 `-1000`，所以会出现 Loss 函数的值小于 0 的情况发生
   > 3. 在梯度下降的算法，从图中可以看出会出现局部最小的情况，但是实际上这并不是梯度下降的主要问题，梯度下降真正的痛点在后面会提到



:red_circle:**总结**

一般而言，机器学习的过程如下：

1. 收集训练数据: $\left\{\left(\boldsymbol{x^1}, y^1\right),\left(\boldsymbol{x^2}, y^2\right), \ldots,\left(\boldsymbol{x^N}, y^N\right)\right\}$

   > [!tip]
   >
   > 其中 $x$ 代表训练数据的输入，即样本，$y$ 代表训练数据的输出，即真值

2. 进行训练

   ```mermaid
   graph LR
   A("Step 1:<br>function with unknown<br>$$y=f_{\theta}(x)$$")
   B("Step 2:<br>loss from training data<br>$$L(\boldsymbol{\theta})$$")
   C("Step 3:<br>optimization<br>$$\boldsymbol{\theta}^*=\arg\  \min _{\boldsymbol{\theta}} L$$")
   A --> B
   B --> C
   ```

   > [!note]
   >
   > 其中训练集需要进一步拆分出一个验证集（validation set），其他的数据集用于训练模型，为了更加充分地利用训练集，我们可能会做 k 折交叉验证（k-fold Cross-Validation)

3. 将训练好的模型运用到测试集中，在一般的数据挖掘和预测的平台，例如 Kaggle，一般只提供 public testing set，而对 private testing set 是隐藏起来避免用户训练模型只是恰好在 public testing set 中的效果好，而在未知数据集上表现一般

   Testing data: $\left\{\left(\boldsymbol{x^{N+1}}, \hat{y}^{N+1}\right),\left(\boldsymbol{x^{N+2}}, \hat{y}^{N+2}\right), \ldots,\left(\boldsymbol{x}^{N+M}, \hat{y}^{N+M}\right)\right\}$

   > [!tip]
   >
   > 一般而言，我们规定 $y$ 代表真值（ground truth），而 $\hat{y}$ 代表预测值（predict value）





**如何针对 loss 对模型进行优化？**

我们可以按照下面的这个流程进行处理

![image-20241003202510975](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241003202510975.png)

👨‍🏫对图示进行部分解释和补充

1. model bias vs optimization issue

   - model bias 即模型偏差，是由于<u>建模过于简单，不够有弹性</u>导致模型在训练集上训练时，无论怎么改变模型参数，误差仍然很大
   - optimization issue 即优化问题，由于在使用 GB 算法存在一个 local minima（局部极小值） 的问题，所以我们可能找到的参数（或参数向量）并不是一个很好的解，导致误差很大

   > [!tip]
   >
   > 如何判断是 model bias 还是 optimization issue?
   >
   > 多添加几个层数更少的 model 进行对比，如果深层神经网络比浅层神经网络误差更大，那么我们考虑此时深层圣经网络没有参数优化没有做好

2. overfitting 只有当我们在做测试时才能判断误差是由过拟合产生的







# 3 深度学习的基本概念

:bulb:**前置知识: sigmoid 函数**

如下即为 sigmoid function 表达式：
$$
y=c\frac{1}{1+e^{-(b+wx)}}=\sigma(b+wx)
$$
<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923131941279.png" alt="image-20240923131941279" style="zoom: 33%;" />

当我们将 sigmoid 函数分段硬直化时，此时的 sigmoid 函数又称为 hard sigmoid，相对而言，我们可以称上述的 sigmoid 函数为 soft sigmoid

最简化的 sigmoid 函数为 $y=\frac{1}{1+e^{-x}}=\sigma(x)$，其导函数 $y^{\prime}=\frac{e^{-x}}{(1+e^{-x})^2}=\sigma(x)\cdot (1-\sigma(x))$

我们可以使用 python 代码实现：

```python
import matplotlib.pyplot as plt
import numpy as np
def sigmoid(x):
  return 1 / (1 + np.exp(-x))


def sigmoid_plot(x):
  y_1 = sigmoid(x)
  y_2 = sigmoid(x) * (1 - sigmoid(x))
  plt.plot(x, y_1, 'b', label='sigmoid')
  plt.plot(x, y_2, 'r', label='sigmoid derivative')
  plt.legend()
  plt.show()


if __name__ == '__main__':
  x = np.arange(-4, 3, 0.2)
  sigmoid_plot(x)
```

![image-20241003155140804](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241003155140804.png)





:question: 问题引入：<u>现在我要根据数据集创建一个模型用来预测一个频道的观看人数，请问该如何构建这个模型？</u>

如果我们使用线性模型，由于线性模型过于简单，在大多数情况下肯定是不适用的，因此我们需要构建一个更加复杂的模型

> [!tip]
>
> 在大部分场景中，线性模型具有比较大的模型偏差（model bias），模型偏差描述了模型预测的平均误差，用符号表示为 $\frac{1}{n}\sum_{i=1}^{n}{|y-\hat{y}|}$



对于下图，假设我们需要构建的函数为红色曲线部分，那么我们可以理解为 *red curve = constant + blue 'Z' curve*

<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923165416649.png" alt="image-20240923165416649" style="zoom: 33%;" />



:arrow_down:how to represent blue 'Z' curve?

**answer**: <u>we can use sigmoid function.</u>

<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923171230582.png" alt="image-20240923171230582" style="zoom: 33%;" />

为了拟合红色曲线，我们可以通过组合多个不同的 sigmoid 函数实现，得到如下式子：
$$
y=\sum_i{c_i\ \sigma(w_ix_1+b_i)} + b
$$
但是上述式仅考虑到一个特征，当有多个特征时，其 model 可以修改为如下式子：
$$
y=\sum_i{c_i\ \sigma(\sum_{j}w_{ij}x_j+b_i)} + b
$$

> - $i$ denotes the no. of sigmoid functions
>
> - $j$ denotes the no. of features
> - $w_{ij}$ denotes the weight for $x_j$ for i-th sigmoid



:arrow_double_down:**进一步解释**

假设我们将累加的加权表达式拆开，我可以可以得到 $r_1, r_2, r_3, \cdots$

![image-20240923175421725](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923175421725.png)

我们将上式转换为矩阵表达式
$$
\begin{aligned}
& r_1=b_1+w_{11} x_1+w_{12} x_2+w_{13} x_3 \\
& r_2=b_2+w_{21} x_1+w_{22} x_2+w_{23} x_3 \\
& r_3=b_3+w_{31} x_1+w_{32} x_2+w_{33} x_3 \\
& \Downarrow
\\
& {\left[\begin{array}{l}
r_1 \\
r_2 \\
r_3
\end{array}\right]=\left[\begin{array}{l}
b_1 \\
b_2 \\
b_3
\end{array}\right]+\left[\begin{array}{lll}
w_{11} & w_{12} & w_{13} \\
w_{21} & w_{22} & w_{23} \\
w_{31} & w_{32} & w_{33}
\end{array}\right]\left[\begin{array}{l}
x_1 \\
x_2 \\
x_3
\end{array}\right]} \\
& \Downarrow
\\
& \boldsymbol{r}=\boldsymbol{b}+W\boldsymbol{x}
\end{aligned}
$$
![image-20240923180712272](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923180712272.png)

![image-20240923180752895](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923180752895.png)

> 上述每一个 sigmoid （对应上图的蓝色小球）我们称之为一个神经元（neuron），整个流程我们称之为一个神经网络，得到的 $a_i$ 仍然可以交叉相乘得到加权表达式 $r$，然后再进行一次 sigmoid 操作，其中同一层次的神经元构成一个隐藏层（hidden layer）

在表达式 $y=b+c^T \sigma(\boldsymbol{b}+W \boldsymbol{x})$ 中，$b, \boldsymbol{c^T}, \boldsymbol{b}, \boldsymbol{W}$ 都是我们要求解的超参数， 所以对于损失函数 $L(\theta)$ 即是由这些参数构成，我们分别对其进行微分，利用梯度下降（GB）进行调参优化即可
$$
\underset{\text { gradient }}{\boldsymbol{g}}=\left[\begin{array}{c}
\left.\frac{\partial L}{\partial \theta_1}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}^0} \\
\left.\frac{\partial L}{\partial \theta_2}\right|_{\boldsymbol{\theta}=\boldsymbol{\theta}^0} \\
:
\end{array}\right]
$$
我们将其简化为 $\boldsymbol{g}=\nabla L\left(\boldsymbol{\theta}^0\right)$

面对大规模的数据集，我们常见的操作不是一次性处理，而不是将整个数据集 $N$ 分割为若干个 batch，然后不断 $\boldsymbol{\theta}$ 得到新的 $\boldsymbol{g}$，一整个流程结束后，我们称为一个 epoch(纪元)。

> [!tip]
>
> 1 epoch = see all the batcher once.

![image-20240923183034250](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923183034250.png)



对于拟合 "Z" 曲线，我们其实除了 sigmoid 函数，也可以考虑使用 Rectified Linear Unit(ReLU) ，其表达式为：
$$
y=c\ max(0, b+wx)
$$
<img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240923203507182.png" alt="image-20240923203507182" style="zoom:50%;" />



**neural network 基本架构**

![image-20241002160646481](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241002160646481.png)



# 4 colab

## 4.1 基本介绍

> Google Colaboratory, or Colab, is an as-a-service [version of Jupyter Notebook](https://www.techtarget.com/searchaws/video/Set-up-a-Jupyter-notebook-on-AWS-with-this-tutorial) that enables you to write and execute Python code through your browser.







## 4.2 使用方法

使用方法：打开 Google Drive，然后创建 Colab 文档像 Jupyter 一样正常使用即可。

1. 如何修改运行时环境？

   [Runtime] → [Change runtime type]

2. 有用的 Linux 命令（在 Colab 中）

   - `ls`
   - `ls -l`
   - `pwd`
   - `mkdir <dirname>`
   - `cd <dirname>`
   - `gdown`: download files from google drive
   - `weget`: download files from the internet
   - `python <python_file>`: execute a python file



查看被分配的 GPU 型号

```python
gpu_info = !nvidia-smi 
gpu_info = '\n'.join(gpu_info) 
if gpu_info.find('failed') >= 0: 
    print('Not connected to a GPU') 
else: 
    print(gpu_info)
```

```
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |
| N/A   64C    P8              13W /  70W |      0MiB / 15360MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
```

从上面的信息，我们可以看到我们被分到的 GPU 是 T4

> [!note]
>
> 可用 GPU 的性能排行为：P100 > T4 > k80, 在大部分时候，我们都是被分配到 k80



1. 挂载自己的谷歌云盘

   ```python
   from google.colab import drive
   drive.mount('/content/drive')
   ```

2. 训练模型

   ```python
   !python3 /content/drive/MyDrive/main.py \
   --data_root /content/drive/MyDrive/dataset/battery \
   --logdir /comtent/drive/MyDrive/ \ --
   resume \
   | tee /comtent/drive/MyDrive/result.txt -a
   ```

   - 第一行主要是运行模型的主程序
   - `--data_root` 指定数据集的根目录
   - `--logdir` 用于指定保持模型的日志（checkpoint + tensorboard）
   - `--resume` 表示如果有 checkpoint 就加载 checkpoint
   - `|` 是管道符，用于流式输入输出
   - `tee` 命令将输出保存到文件的同时输出到屏幕，`-a` 代表追加模型













# 5 PyTorch

## 5.1 基本介绍

### 5.1.1 什么是 PyTorch

- An open source **machine learning framework**
- A python package that provides two high-level features:
  - Tensor computation(like NumPy) with strong **GPU acceleration**
  - Deep neural networks built on a **tape-base automatic gradient** system 

**PyTorch :vs: TensorFlow**

|             | PyTorch     | TensorFlow             |
| ----------- | ----------- | ---------------------- |
| Developer   | Facebook AI | Google Brain           |
| Interface   | Python, C++ | Python, C++, JS, Swift |
| Debug       | easy        | difficult              |
| Application | Research    | Production             |

![image-20240930172307539](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240930172307539.png)



### 5.1.2 什么是 Tensor

Tensor(张量)即一个高维矩阵

![image-20240930174609733](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240930174609733.png)

- 0-1 tensor: scalar
- 1-D tensor: vector
- 2-D tensor: matrix
- 3-D tensor: multi-matrix

Tensor 对象三个基本属性：

1. `rank`: number of dimensions
2. `shape`: number of rows and columns
3. `type`: data type of tensor's elements

**Tensor Constructor**

1. from list/NumPy array

   ```python
   # construct a 2-D tensor
   x = torch.tensor([[1, 2], [3, 4]])
   
   # construct a 2-D tensor
   x = torch.tensor([[1, 2], [3, 4]])
   ```

2. Zero tensor

   ```python
   # construct a 2*2 matrix filled with zero
   x = torch.zeros([2, 2])
   ```

3. Unit tensor

   ```python
   # construct a 1*2*5 tensor
   x = torch.ones([1, 2, 5])
   ```



**Tensor operators**

1. `torch.squeeze`: Returns a tensor with all specified dimensions of `input` of size 1 removed. When `dim` is given, a squeeze operation is done only in the given dimension(s).(begin with 0)

   ```python
   torch.squeeze(input, dim=None) -> Tensor
   ```

   > [!note]
   >
   > `squeeze` 函数主要用于维度压缩，默认情况下将大小为 1 的维度抹除，也可以使用参数 dim 指定要删除的维度 

   ```python
   >>> x = torch.tensor([[[1, 2, 3], [4, 5, 6]]])
   >>> x.size()
   torch.Size([1, 2, 3])
   
   >>> x = torch.squeeze(x)
   >>> x.size()
   torch.Size([2, 3])
   ```

2. `torch.unsqueeze`: Returns a new tensor with a dimension of size one inserted at the specified position. $dim \in [-input.dim()-1, input.dim()+1]$

   ![image-20240930210101666](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240930210101666.png)

   ```python
   torch.unsqueeze(input, dim) -> Tensor
   ```

   示例代码

   ```python
   >>> x = torch.tensor([1, 2, 3, 4])
   >>> y_1 = torch.unsqueeze(x, 0)
   >>> y_1, y_1.shape
   (tensor([[1, 2, 3, 4]]), torch.Size([1, 4]))
   
   >>> y_2 = torch.unsqueeze(x, 1)
   >>> y_2, y_2.shape
   (tensor([[1],
            [2],
            [3],
            [4]]),
    torch.Size([4, 1]))
   ```

   > [!note]
   >
   > 该函数是压缩的反向操作，用于对 tensor 在指定位置进行扩展

3. `tensor.transpose`: Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.

   ```python
   >>> x = torch.randn(2, 3)
   >>> x
   tensor([[-0.3842,  1.4757, -1.3104],
           [-0.6988, -0.6478,  0.4628]])
   
   >>> torch.transpose(x, 0, 1)
   tensor([[-0.3842, -0.6988],
           [ 1.4757, -0.6478],
           [-1.3104,  0.4628]])
   ```

   >[!note]
   >
   >该函数主要用于维度调换

4. `torch.cat`: concatenate multi tensors

   ```python
   >>> x = torch.zeros([2, 1, 3])
   >>> y = torch.zeros([2, 2, 3])
   >>> z = torch.zeros([2, 3, 3])
   >>> w = torch.cat([x, y, z], dim=1)
   >>> w.shape
   torch.Size([2, 6, 3])
   ```

5. basic operators

   - Addition: `z = x + y`
   - Subtraction: `z = x - y`
   - Power: `y = x.pow(2)`
   - Summation: `y = x.sum()`
   - Mean: `y = x.mean()`

6. get Attributes

   | PyTorch            | NumPy                |
   | ------------------ | -------------------- |
   | x.shape            | x.shape              |
   | x.dtype            | x.dtype              |
   | x.reshape / x.view | x.reshape            |
   | x.squeeze()        | x.squeeze()          |
   | x.unsqueeze(1)     | np.expand_dims(x, 1) |

   

**Tensor - device**

- default: tensors & modules will be computed with **CPU**

- CPU

  ```python
  x = x.to('cpu')
  ```

- GPU

  ```python
  x = x.to('cuda')
  
  # check if you are qualified to use GPU
  torch.cuda.is_available()
  ```



**calculate gradient**

1. $x=\left[\begin{array}{cc}
   1 & 0 \\
   -1 & 1
   \end{array}\right]$ , $z=\sum_i \sum_j x_{i, j}^2$
2. $\frac{\partial z}{\partial x_{i,j}}=2 x_{i, j}$
3. $\frac{\partial z}{\partial x}=\left[\begin{array}{cc}
   2 & 0 \\
   -2 & 2
   \end{array}\right]$

使用 PyTorch 进行计算

```python
x = torch.tensor([[1., 0.], [-1., 1.]], requires_grad=True)
z = x.pow(2).sum()
z.backward()
x.grad
```



### 5.1.3 使用流程

![image-20241001174028890](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241001174028890.png)



`Dataset` 是一个抽象类，里面有很多数据集可以直接调用，也可以自定义数据集，如果我们要自定义数据集，那么需要继承 Dataset, 并且重写 `__getitem__()`

`DataLoader` 主要用于加载数据

```python
class MyDataset(Dataset):
    def __init__(self, data):
        self.data = data
    def __getitem__(self, idx):
        return self.data[idx]
    def __len__():
        return len(self.data)

my_dataset = MyDataset(file)
dataloader = DataLoader(my_dataset, batch_size, shuffle=True)  
```

![image-20241001174253049](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241001174253049.png)



### 5.1.4 Neural Network Layers

- Linear Layer(Fully-connected Layer)

  ```python
  nn.Linear(in_features, out_features)
  ```

  ![image-20241001175104819](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241001175104819.png)

  ![image-20241001175334181](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241001175334181.png)

  > $\boldsymbol{W}$ 是全连接层的矩阵

  ```python
  # weight: the learnable weights of the module of shape
  layer = torch.nn.Linear(32, 64)
  # get shape of weight in layer
  layer.weight.shape
  # get shape of bias in layer
  layer.bias.shape
  ```

- Activation Functions

  - Sigmoid: `nn.sigmoid`
  - ReLu: `nn.ReLu`

- Loss Functions

  - Mean Squared Error(for linear regression): `nn.MSELoss()`
  - Cross Entropy(for classification): `nn.CrossEntropyLoss()`

- torch.optim

  - Stochastic Gradient Descent(SGD)

    ```python
    torch.optim.SGD(params, lr, momentum=0)
    ```



### 5.1.5 construct Neural Network

**build a neural network**

```python
import torch.nn as nn
class MyModel(nn.Module):
    # initialize your model & define layers
    def __init__(self):
        super(MyMoulde, self).__init__()
        self.net = nn.Sequential(
            # add a linear layer
            nn.Linear(10, 32),
            # deal with a sigmoid function
            nn.Sigmoid(),
            # add a linear layer again
            nn.Linear(32, 1)
        )
    # compute output of your NN
    def forward(self, x):
        return self.net(x)
```



**neural network training**

```python
dataset = MyDataset(file)                            # read data via Dataset
tr_set = DataLoader(dataset, 16, shuffle=True)       # put dataset into DataLoader
model = MyModel().to(device)                         # construct a model and move to device
criterion = nn.MSELoss()                             # set loss function
optimizer = torch.optim.SGD(model.parameters(), 0.1) # set optimizer
```



## 5.2 环境配置

提前安装好 Adaconda or Miniconda, 配置好 conda 环境

1. 创建一个独立的 python 环境并进入

   ```shell
   conda create -n pytorch python
   
   conda activate pytorch
   ```

   > [!caution]
   >
   > 不要使用国内镜像源进行创建 pytorch 环境

2. 进入 [PyTorch](https://pytorch.org/) 官网安装 PyTorch，根据有无 N 卡、开发语言、开发平台选择相应的 command 进行安装

3. 验证 torch 是否安装成功：进入 python 命令行，输入以下命令，如果没有报错代表安装成功

   ```python
   import torch
   # 验证 GPU 是否可以使用（仅限带有 N 卡并且安装了 cuda）
   torch.cuda.is_available()
   ```

4. 在创建的 PyTorch 环境中安装 Jupyter

   ```shell
   # 进入 pytorch 环境
   conda activate pytorch
   # 安装 conda 环境中用于支持 jupyter 的包
   conda install nb_conda
   ```

5. 验证 jupyter 是否可以使用

   ```shell
   jupyter notebook	
   ```



## 5.3 使用方法

### 5.3.1 两大法宝函数

1. `dir()`：能让我们知道工具包以及工具包中的分隔区有什么东西

   ```shell
   import torch
   # 查看 cuda 是否可用
   torch.cuda.is_available()
   # dir 查看 torch 具体工具包中所含有的内容
   dir(torch)
   # 进一步查看 torch.cuda 中所包含的内容
   dir(torch.cuda)
   ```

2. `help()`：能让我们知道每个工具是如何使用的，即工具的使用方法

   ```shell
   # 查看 torch.cuda 中的 _device 函数
   help(torch.cuda._device)
   ```



### 5.3.2 数据集导入

- `torch.utils.data.dataset`: An abstract class representing a Dataset. All datasets that represent a map from keys to data samples should subclass it. All subclasses should overwrite `__getitem__()`
- `torch.utils.data.DataLoader`：Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.



Dataset 的使用

1. 引入相应的库

   ```python
   from torch.utils.data import Dataset
   from PIL import Image
   import os
   ```

2. 构建一个继承 Dataset 的类 MyData

   ```python
   class MyData(Dataset):
       def __init__(self, root_path, label_path):
           # root_path 文件所在文件夹的父级路径; label_path 文件所在文件夹的路径
           self.root_path = root_path
           self.label_path = label_path
           # 图片文件所在文件文件夹的完整路径
           self.path = os.path.join(self.root_path, self.label_path)
           self.img_path = os.listdir(self.path)
   	
       # 重写 __getitem__ 方法
       def __getitem__(self, idx):
           img_name = self.img_path[idx]
           img_item_path = os.path.join(self.path, img_name)
           img = Image.open(img_item_path)
           return img, self.label_path
   
       def __len__(self):
           return len(self.img_path)
   ```

3. 假设现在在 root 路径下有两个存放图片集的文件夹，一个是 ants，另一个是 bees，然后我们通过创建的 MyData 类进行读取数据集，再进行合并

   ```python
   if __name__ == '__main__':
       root_path = 'D:\\Download\\BaiduNetdisk\\dataset\\hymenoptera_data\\train'
       ants_label_path = 'ants'
       bees_label_path = 'bees'
       ants_dataset = MyData(root_path, ants_label_path)
       bees_dataset = MyData(root_path, ants_label_path)
       train_dataset = ants_dataset + bees_dataset
   ```

4. 对合并的数据进行操作

   ```python
   img, label = train_dataset[100]
   len(train_dataset)
   ```



### 5.3.3 TensorBoard

TensorBoard 是一组用于数据可视化的工具。它包含在流行的开源机器学习库 Tensorflow 中。TensorBoard 的主要功能包括：

- 可视化模型的网络架构
- 跟踪模型指标，如损失和准确性等
- 检查机器学习工作流程中权重、偏差和其他组件的直方图
- 显示非表格数据，包括图像、文本和音频
- 将高维嵌入投影到低维空间

:rocket: **安装 TensorBoard**

```shell
conda install -c conda-forge tensorboard
```

:pencil2:使用 tensorboradX 数据库来训练标量数据

```python
from tensorboardX import SummaryWriter
# 创建 SummaryWriter 实例，并指定日志文件保存在 logs 目录下
writer = SummaryWriter('logs')
# writer.add_image()
for i in range(100):
    # 添加标量，其中 tag 代表标题，第二个参数 scalar_value 相当于坐标轴中的 y，第三个参数 global_step 相当于坐标轴中的 x
    writer.add_scalar('y=x', i, i)
writer.close()
```

启动 tensorboard ，在控制台输入如下命令：

```shell
tensorboard --logdir=logs --port=6007
```

> [!tip]
>
> 保留的日志文件仍然会显示在留在 logs 中，如果想要擦除之前的拟合曲线需要将对应的日志删除





:point_right: **使用 tensorboard 处理图像​**

SummaryWriter 实例的 `add_image()` 的参数 img_tensor 有特定的限制，如下：

```python
img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data
```

因此，我们需要使用 opencv 进行读取图像，在这之前，需要下载安装好 opencv 库

```shell
pip install opencv-python
```

实现代码如下：

```python
from torch.utils.tensorboard import SummaryWriter
from PIL import Image
import numpy as np

writer = SummaryWriter('logs')
image_path = 'dataset/train/ants_image/0013035.jpg'
img_PIL = Image.open(image_path)
img_array = np.array(img_PIL)

writer.add_image("test", img_array, 1, dataformats='HWC')

writer.close()
```



### 5.3.4 transforms

transforms 是一个工具箱，用来将未处理的数据形式处理成为我们最后想要的数据形式。

transforms 位于工具包 torchvision 下，torvision 下主要有三个模型：

1. `torchvision.transforms`：提供了常用的一系列图像预处理方法，例如数据的标准化，中心化，旋转，翻转等。
2. `torchvision.datasets`：定义了一系列常用的公开数据集的datasets，比如MNIST，CIFAR-10，ImageNet等。
3. `torchvision.model`：提供了常用的预训练模型，例如 AlexNet，VGG，ResNet，GoogLeNet等。

:pencil2:**通过 transforms 工具箱将图片转换为一个 Tensor**

```python
from torchvision import transforms
from PIL import Image

img_path = 'D:\\Document\\PyProject\\pytorch\\dataset\\train\\ants_image\\0013035.jpg'
img = Image.open(img_path)

# 使用 transforms 创建一个 Tensor 对象
tensor_trans = transforms.ToTensor()
# 调用 Tensor 对象（对应 __call__ 函数），使得图片转换为 tensor
tensor_img = tensor_trans(img)
```



**:gift:附加函数解析**

1. `__call()__`：属于一种 magic method，作用是将一个类的实例化对象转换为可调用对象

   ```python
   class Person:
       def __init__(self, name):
           self.name = name
   
       def __call__(self):
           print('Hello!', self.name)
   
   
   p = Person('john')
   # 调用方式 1（recommend）
   p()
   # 调用方式 2
   p.__call__()
   ```

2. `transforms.ToTensor()`：将 PIL 图像或 ndarray 转换为一个 tensor 并且相应地缩放它的值

   ```python
   import numpy as np
   from torchvision import transforms
   
   # 使用 transforms.Compose 将多个 transforms 函数组合使用
   trans = transforms.Compose([transforms.ToTensor()])
   
   d1 = [1, 2, 3, 4, 5, 6]
   d2 = [4, 5, 6, 7, 8, 9]
   d3 = [7, 8, 9, 10, 11, 14]
   d4 = [11, 12, 13, 14, 15, 15]
   d5 = [d1, d2, d3, d4]
   d = np.array([d5, d5, d5], dtype=np.float32)
   
   d.shape # (3, 4, 6)
   b = trans(d)
   b.shape # torch.Size([6, 3, 4])
   ```

   > [!note]
   >
   > `transforms.ToTensor()` 将 PIL Image 或者 `numpy.ndarray (H x W x C)` 转换为一个 `torch.FloatTensor(C x H x W)`，其中 C(channel) ，代表图像的色彩通道数目，H(Height)，代表图像的高度，W(Width)，代表图像的宽度

3. `transforms.resize()`： 将输入的图像转换为指定尺寸大小

   ```python
   from torchvision import transforms
   from PIL import Image
   
   img = Image.open('D:\\Document\\PyProject\\pytorch\\dataset\\train\\ants_image\\0013035.jpg')
   
   print(img.size)  # (768, 512)
   
   trans_size = transforms.Resize((512, 512))
   img_resize = trans_size(img)
   print(img_resize.size)  # (512, 512)
   ```

4. `transforms.Normalize(mean, std)`：输入 `(C, H, W)` 形式的 tensor，对每层进行标准化后输出，即
   $$
   \text { output }[\text { channel }]=\frac{\text { input }[\text { channel }]-\text { mean }[\text { channel }]}{\operatorname{std}[\text { channel }]}
   $$
   



### 5.3.5 torvision 中的数据集

> [!tip]
>
> Reference: https://pytorch.org/vision/stable/datasets.html

**:rocket:使用 [CIFAR10](https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10) 数据集进行练手**

```python
import torchvision

train_set = torchvision.datasets.CIFAR10(root='./datasets', train=True, download=True)
test_set = torchvision.datasets.CIFAR10(root='./datasets', train=False, download=True)

# 查看测试集数据
print(test_set[0])
# 查看该数据集的类别（对应的就是标签标记）
print(test_set.classes)
# 对训练集进行解包
img, target = train_set[0]
# 打开图片
img.show()
```



### 5.3.6 DataLoader

> [!tip]
>
> Reference: https://pytorch.org/docs/stable/data.html

`Dataloader` 主要用于装载数据，其函数签名如下：

```python
DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,
           batch_sampler=None, num_workers=0, collate_fn=None,
           pin_memory=False, drop_last=False, timeout=0,
           worker_init_fn=None, *, prefetch_factor=2,
           persistent_workers=False)
```

:raising_hand_man:**示例代码**

```python
import torchvision
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
# 添加 transform 参数用于将 PIL 格式的数据转换为 tensor
test_set = torchvision.datasets.CIFAR10(root='./datasets', train=False, download=True, transform=torchvision.transforms.ToTensor())

# 加载数据，batch_size 每个 batch 中加载的数据的个数, num_workers 代表使用的线程数（值为 0 代表使用的是主线程）, drop_list 是否保留经过 batch 处理后剩余的数据
test_loader = DataLoader(dataset=test_set, batch_size=64, shuffle=True, num_workers=0, drop_last=True)

writer = SummaryWriter('logs')
step = 0
for data in test_loader:
    # 解包获取 data 中的值
    images, targets = data
    writer.add_images("test_data", images, step)
    step += 1

writer.close()
```



### 5.3.7 神经网络的基本骨架 - nn.Module 的使用

> [!tip]
>
> Reference: https://pytorch.org/docs/stable/nn.html

:pencil2:**示例代码**

```python
from torch import nn


# 创建一个简单的模型，该模型用于将输入的值加一
class Model(nn.Module):
    # 调用父类的 init 方法进行初始化
    def __init__(self):
        super(Model, self).__init__()

    # @staticmethod
    def forward(self, in_put):
        out_put = in_put + 1
        return out_put


model = Model()
op = model.forward(1)
print(op)
```



### 5.3.8 convolution

> [!tip]
>
> Reference: https://pytorch.org/docs/stable/nn.html#convolution-layers

对 [Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) 的解析

- Input: $(N, C_{in}, H_{in}, W_{in})$ or $(C_{in}, H_{in}, W_{in})$
- Output: $(N, C_{out}, H_{out}, W_{out})$ or $(C_{out}, H_{out}, W_{out})$


$$
\begin{aligned}
H_{\text{out}} &= \left\lfloor \frac{H_{\text{in}} + 2 \times \text{padding}[0] - \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1 \right\rfloor \\
W_{\text{out}} &= \left\lfloor \frac{W_{\text{in}} + 2 \times \text{padding}[1] - \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1 \right\rfloor
\end{aligned}
$$






:pencil2:**示例代码**

```python
import torch
import torch.nn.functional as F

# 输入图像
input_img = torch.tensor([
    [1, 2, 0, 3, 1],
    [0, 1, 2, 3, 1],
    [1, 2, 1, 0, 0],
    [5, 2, 3, 1, 1],
    [2, 1, 0, 1, 1]
])
# 卷积核
kernel = torch.tensor([
    [1, 2, 1],
    [0, 1, 0],
    [2, 1, 0]
])

# 重塑输入图像的 tensor, 在参数 shape 中，元组的第一个参数代表 batch_size=1, 第二个参数代表色彩通道数channel=1, 第三个参数代表图片高度Height=5, 第四个参数代表图片宽度Width=5
input_channel = torch.reshape(input_img, (1, 1, 5, 5))
kernel = torch.reshape(kernel, (1, 1, 3, 3))

# 开始进行卷积操作, stride 控制卷积核卷积的步长
output = F.conv2d(input_channel, kernel, stride=1)
print(output)
```



:paperclip:**卷积解析**

**Convolution animations**

> [!tip]
>
> *N.B.: Blue maps are inputs, and cyan maps are outputs.*

| No padding, no strides                                       | Arbitrary padding, no strides                                | Half padding, no strides                                     | Full padding, no strides                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![no_padding_no_strides](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/no_padding_no_strides.gif) | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/arbitrary_padding_no_strides.gif" alt="arbitrary_padding_no_strides" style="zoom: 48%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/arbitrary_padding_no_strides_transposed.gif" alt="arbitrary_padding_no_strides_transposed" style="zoom: 54%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/full_padding_no_strides.gif" alt="full_padding_no_strides" style="zoom:45%;" /> |
| **No padding, strides=2**                                    | **Padding, strides=2**                                       | **Padding, strides (odd)**                                   |                                                              |
| ![no_padding_strides](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/no_padding_strides.gif) | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/padding_strides.gif" alt="padding_strides" style="zoom: 67%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/padding_strides_odd.gif" alt="padding_strides_odd" style="zoom: 67%;" /> |                                                              |

> [!note]
>
> padding 参数用于填充输入的四边，默认零填充



**示例代码：将图片进行卷积操作**

```python
import torch
import torchvision as tv
from torch.utils.data import DataLoader
from torch import nn
from torch.utils.tensorboard import SummaryWriter


class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3, stride=1, padding=0)

    def forward(self, x):
        x = self.conv(x)
        return x


def main():
    train_dataset = tv.datasets.CIFAR10('datasets', train=True, transform=tv.transforms.ToTensor(), download=True)
    dataloader = DataLoader(train_dataset, batch_size=64)
    writer = SummaryWriter('logs')
    m = Model()
    step = 0
    for data in dataloader:
        images, targets = data
        output = m(images)
        # shape 中的 -1 代表 batch_size 自动调整
        output = torch.reshape(output, (-1, 3, 30, 30))
        writer.add_images('input', images, step)
        writer.add_images('output', output, step)
        step += 1
    writer.close()


if __name__ == '__main__':
    main()
```



### 5.3.9 pooling layers

> [!tip]
>
> Reference: https://pytorch.org/docs/stable/nn.html#pooling-layers

池化层有很多函数可供我们选择，我们主要了解 [MaxPool2d](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d) 该如何使用



:gift:**空洞卷积**​

空洞卷积（Dilated Convolutions）也被称为膨胀卷积，主要是为了解决图像分割的问题。

空洞卷积引入了一个 "扩张率"(dilation rate)的超参数，该参数定义了卷积核处理数据时各值的间距。

| <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/dilation.gif" alt="dilation" style="zoom:102%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240926205006924.png" alt="image-20240926205006924" style="zoom: 72%;" /> |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

---

对于 MaxPool2d，我们用下面的图来展示其计算过程

![image-20240926214926669](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240926214926669.png)

**示例代码**

```python
import torch
from torch.nn import MaxPool2d
from torch import nn


class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.MaxPool_1 = MaxPool2d(kernel_size=3, ceil_mode=True)

    def forward(self, x):
        return self.MaxPool_1(x)


def main():
    input_matrix = torch.tensor([
        [1, 2, 0, 3, 1],
        [0, 1, 2, 3, 1],
        [1, 2, 1, 0, 0],
        [5, 2, 3, 1, 1],
        [2, 1, 0, 1, 1]
    ], dtype=torch.float32)
    input_matrix = torch.reshape(input_matrix, (-1, 1, 5, 5))
    m = Model()
    output = m(input_matrix)
    print(output)


if __name__ == '__main__':
    main()
```



在卷积神经网络中，相邻的卷积层之间通常会添加一个池化层，用于缩小参数矩阵的尺寸，从而减少最后连接层中的参数数量，所以加入池化层可以加快计算速度和防止过拟合，最典型的应用场景就是压缩图片（将 1024\*1024像素的图片压缩到800\*800）



### 5.3.10 非线性激活

> [!tip]
>
> Reference:
>
> - ReLu: https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU
> - Sigmoid: https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid

我们常使用的两个非线性激活函数分别是：

|                     `torch.nn.Sigmoid()`                     |                `torch.nn.ReLU(inplace=False)`                |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| $\operatorname{Sigmoid}(x)=\sigma(x)=\frac{1}{1+\exp (-x)}$  |         $\operatorname{ReLu}(x)=(x)^{+}=\max (0, x)$         |
| ![image-20240926233823171](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240926233823171.png) | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240926233945856.png" alt="image-20240926233945856" style="zoom:105%;" /> |



### 5.3.11 Sequential

> [!tip]
>
> Reference: https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#sequential

A sequential container. Modules will be added to it in the order they are passed in the constructor.





将下图的过程使用 `Sequential` 进行解决

![image-20240927103408609](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20240927103408609.png)

**代码**

```python
import torch
from torch import nn
from torch.utils.tensorboard import SummaryWriter


class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.seq = nn.Sequential(
            nn.Conv2d(3, 20, 5, padding=0),
            nn.MaxPool2d(2),
            nn.Conv2d(20, 50, 5, padding=0),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(800, 500),
            nn.Linear(500, 10)
        )

    def forward(self, x):
        return self.seq(x)


def main():
    m = Model()
    input_data = torch.ones(64, 3, 28, 28)
    output_data = m(input_data)
    
    writer = SummaryWriter('logs')
    writer.add_graph(m, input_data)
    writer.close()
    

if __name__ == '__main__':
    main()
```

> [!tip]
>
> 对于二维卷积而言，确定 padding 值的大小可用上述 $W_{out}$ 或 $H_{out}$ 的公式进行判断



### 5.3.12 损失函数与反向传播

> [!tip]
>
> Reference: https://pytorch.org/docs/stable/nn.html#loss-functions

- [`nn.L1Loss`](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html#torch.nn.L1Loss)：使用 L1 范式计算损失
- [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)：使用 L2 范式计算损失

```python
import torch
from torch import nn

predict = torch.tensor([1, 2, 3], dtype=torch.float32)
ground_truth = torch.tensor([1, 2, 5], dtype=torch.float32)

loss_1 = nn.L1Loss()
loss_2 = nn.MSELoss()
result_1 = loss_1(predict, ground_truth)
result_2 = loss_2(predict, ground_truth)
```



# 6 Backpropagation

 GB（Gradient Descent） 的运行原理：

1. 假如 Network parameters $\theta={w_1, w_2, \cdots, b_1, b_2, \cdots}$

2. 不断迭代参数列表，$\theta^0 \longrightarrow \theta^1 \longrightarrow \theta^2 \longrightarrow \ldots \ldots$

   ![image-20241002191916349](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241002191916349.png)

   

对于 $\nabla \mathrm{L}(\theta)$ 而言，它里面的参数可能有上百万个，所以计算式相当耗费时间的，而 backpropagation 就是用来优化这一问题的

> [!tip]
>
> 换言之，backpropagation 本质就是优化过的梯度下降算法



**:bulb:Chain Rule**

- Case 1: $y=g(x),\   z=h(y)$
  $$
  \frac{dz}{dx}=\frac{dz}{dy}\cdot \frac{dy}{dx}
  $$

- Case 2: $x=g(s), \ y=h(s), \ z=k(x, y)$
  $$
  \frac{d z}{d s}=\frac{\partial z}{\partial x} \frac{d x}{d s}+\frac{\partial z}{\partial y} \frac{d y}{d s}
  $$

---

![image-20241002203017870](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241002203017870.png)

假设在一个 neural network 中，权重矩阵为 $[w_1, w_2]$, 偏置项为 $b$，输出函数为 $z=x_1w_1+x_2w_2+b$，代价函数 $C$

> [!note]
>
> cost function & loss function & objective function

$$
\frac{\partial{C}}{\partial{w}} = \frac{\partial{Z}}{\partial{w}} \cdot \frac{\partial{C}}{\partial{Z}}
$$

- Forward pass: compute $\frac{\partial{C}}{\partial{w}}$ for all parameters
- Backward pass: compute $\frac{\partial{C}}{\partial{Z}}$ for all activation function inputs z

![image-20241002211320057](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241002211320057.png)

对于 Forward pass 还是比较好算的，例如 $\frac{\partial{C}}{\partial{w_1}}=x_1$，但是对于 Backward pass 就比较难计算，此时我们就需要使用上述方式进行计算

> [!caution]
>
> 推导待续...





# 7 logistic regression

![image-20241003113200929](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241003113200929.png)



# 8 类神经网络训练不起来如何处理

## 8.1 critical point

在 GB 中，正是由于 Critical point 的存在，使得我们无法得到参数的最优解

> [!tip]
>
> Critical point is also called **Stable point** or **Stationary point**

Critical point 可以分为鞍点（saddle point）和极值点（extreme value point），其中极值点又有极大值（local maximum）和极小值（local minimum），他们的复数形式为 local maxima 和 local minima

|                         local minima                         |                         saddle point                         |                         local maxima                         |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004003530780.png" alt="image-20241004003530780" style="zoom:110%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004003725209.png" alt="image-20241004003725209" style="zoom:115%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004003738161.png" alt="image-20241004003738161" style="zoom: 120%;" /> |

在 GB 中，我们的主要目的是为了使得 $loss \rightarrow 0$，所以在这里我们仅考虑 local minima 和 saddle point 两种情况，根据上述情况，如果我们遇到的是 local minima，那么周围就没有办法再继续优化，但如果我们遇到的事 saddle point，那么虽然前后已经没有办法优化，但是可以在左右两边进行优化

---

:apple:**判别 saddle point 和 local minima**

对于某一个 model，它的函数表达式为 $L(\boldsymbol{\theta})$, 其在 $\boldsymbol{\theta}=\boldsymbol{\theta}^{\prime}$ 处的值可以近似代表为如下式子：
$$
L(\theta) \approx L(\textcolor{blue}{\theta'}) + \textcolor{green}{(\theta - \theta')^T \mathbf{g}} + \frac{1}{2} (\theta - \theta')^T \textcolor{red}{\mathbf{H}} (\theta - \theta')
$$

> [!tip]
>
> 1. $g$ 代表 $L(\boldsymbol{\theta}) 在 $ $\boldsymbol{\theta}=\boldsymbol{\theta}^{\prime}$ 处的梯度，i.e., $\mathbf{g}=\nabla_\theta L\left(\theta^{\prime}\right)$
> 2. $H$ 是 $\boldsymbol{\theta}=\boldsymbol{\theta}^{\prime}$ 处的二次微分时的 Hessian Matrix
> 3. 上述式子为 Taylor 展开式的前三项

当在 critical point 处时，$g=0$, 而等式的第一项 $L({\theta'})$ 为常数，所以我们只需要对第三项的值进行判断，假设 $v=\theta - \theta'$，那么:

![image-20241004104544364](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004104544364.png)

如果是 saddle point, 那么我们就可以根据 $H$ 进行调整

实际上，我们遇到 local minima 的情况是少数，大部分都是 saddle point，因此我们可以找到更多的方向去更新优化我们的 loss

![image-20241004111906809](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004111906809.png)



## 8.2 Batch

在 optimization 的过程中，我们经常使用 Batch，即在优化参数 $\theta$ 的时候，不会直接拿出所有的训练数据，然后一起使用去优化模型，而是将训练数据切割为若干个 batch，然后用后一个 batch 去优化前一个 batch 处理过的 $\theta$，不断这么迭代，迭代一个周期我们称之为一个 epoch。

![image-20241004113215473](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004113215473.png)

那么，我们为什么要使用 batch，使用 batch 有什么好处？

假设 example=20, 我们设置 batch_size=20 和 batch_size=1，情况如下

![image-20241004114800573](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004114800573.png)

可以看到

- 对于 full batch，计算时间较长但是 "走" 地更加平稳
- 对于 batch_size=1，能快速得到每一次的实验结果，但是 "走" 地更加曲折



:bulb:比较 batch 较大和较小的情况下所耗费时间的实验结果

- 较大的 batch 在一定范围内，由于 GPU 具有并行运算的处理能力，所以每次更新所耗费的时间并不会特别大，超过其并行运行处理能力后，每次更新所耗费的时间会陡升

  ![image-20241004120532494](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004120532494.png)

- 较小的 batch 每次更新耗费的时间小，但是完成一个 epoch 所耗费的时间并不小，在**控制 sample 的数量不变的情况**下，"Time for one update" - "batch size" 和 "Time for one epoch" - "batch size" 的变化曲线是相反的

  ![image-20241004121017276](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004121017276.png)



:cocktail:结论：较小的 batch 并不会比较大的 batch 的时间开销更小，反而有可能会更大

比较 accuracy - batch_size 的变化曲线

![image-20241004150330825](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004150330825.png)

:thought_balloon:思考：为什么 batch_size 越小，模型越精确，往往会有更好的性能？

![image-20241004153430204](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004153430204.png)

上面给出一张图提供一种解释，batch_size 越小，在每个 batch 中会形成自己的函数曲线，使得最终的 model 更加平滑，也就是说

<b style="color: orange">"Noisy" update is better for training.</b>

那么，我们进一步思考，small batch 是否在 testing dataset 上也有好的结果呢？

![image-20241004155555464](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004155555464.png)

实验证实 small batch 在 testing dataset 上也有好的结果，上述提供了一种解释：

1. Training dataset 和 Testing dataset 拥有不同的数据分布
2. 当我们遇到 Flat Minima 时，在两类数据集上的 loss 之差不会太大；但是当我们遇到 Sharp Minima 时，从图示中我们可以看到 loss 之差就非常大
3. 我们使用 small batch 更容易遇到 Flat Minima ，而 large batch 更容易遇到 Sharp Minima



## 8.3 Momentum

momentum 即 "动量"，在 (vanilla) Gradient Descent 算法中，$\boldsymbol{\theta}$ 移动的方向经常是 $\nabla L(\theta)$ 的反方向，而加上 momentum 之后，使得 $\theta$ 移动的方向是结合上一步移动的动量和当前的 gradient

|                              GB                              |                        GB + Momentum                         |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004163853489.png" alt="image-20241004163853489" style="zoom:152%;" /> | ![image-20241004164001432](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004164001432.png) |

 

## 8.4 Adaptive Learning Rate

### 8.4.1 Adagrad

> [!warning]
>
> Training stuck ≠ Small Gradient（训练卡住不代表梯度很小）

当我们使用 GB 算法不断进行迭代时，loss 会越来越小，最后卡在某个区间来回震荡，这个时候人们会认为已经到了 critical point，其实不然，实际上，gradient 只能趋近 0，如果想要真正达到 0 一般是不可能的，这与我们设置的 learning rate $\eta$ 有关

![image-20241004191625170](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004191625170.png)

但是如果我们将 $\eta$ 设置的非常小，在较为平滑的曲面上又会难以前进，因此对 $\eta$ 的设置不能 one-size-fits-all（一刀切）

所以我们就可以引入一个思想：<b style="color: orange">Different parameters needs different learning rate</b>

在坡度大的地方，$\eta$ 就变大；在坡度小的地方，$\eta$ 就变小

原来我们的 $\theta_i$  update 表达式如下：
$$
\boldsymbol{\theta}_i^{\boldsymbol{t}+\mathbf{1}} \leftarrow \boldsymbol{\theta}_i^{\boldsymbol{t}}-\eta\boldsymbol{g}_i^{\boldsymbol{t}}
$$

> [!tip]
>
> - $i$：model 编号
> - $t$：迭代次数

现在结合 **Root Mean Square** 改变 update 表达式
$$
\begin{aligned}
&\begin{gathered}
\boldsymbol{\theta}_i^{\boldsymbol{t}+\mathbf{1}} \leftarrow \boldsymbol{\theta}_i^{\boldsymbol{t}}-\frac{\eta}{\sigma_i^t}\boldsymbol{g}_i^{\boldsymbol{t}} \\
\sigma_i^t=\sqrt{\frac{1}{t+1} \sum_{k=0}^t\left(\boldsymbol{g}_i^{\boldsymbol{k}}\right)^2}
\end{gathered}\\
&\text { Used in Adagrad }
\end{aligned}
$$
对于上式，$learning\ rate(lr) = \frac{\eta}{\sigma_i^t}\boldsymbol{g}_i^{\boldsymbol{t}} $ , 其中 $\eta$ 是固定的，$g \uparrow \ \rightarrow \sigma\uparrow\ \rightarrow \ lr\downarrow$



### 8.4.2 ​RMSProp

RMSProp （root mean square prop, 均方根传递）也是一个自适应学习率的优化算法，它主要视为解决 Adagrad 在迭代过程中，由于坡度逐平缓，学习率 $lr$ 趋近于 0，无法继续推进的情况发生，所以我们希望提出一种方法来在这时候手动调整，将原来的 $\sigma_t$ 更改为如下式子：
$$
\begin{aligned}
& \sigma_i^{t}=\sqrt{\alpha\left(\sigma_i^{t-1}\right)^2+(1-\alpha)\left(g_i^t\right)^2} \\
& s.t.\  \alpha \in (0, 1)
\end{aligned}
$$

> [!tip]
>
> 这个 $\alpha$ 是 hyper parameter，是我们可以手动调整的



### 8.4.3 Learning Rate Scheduling

![image-20241004210456383](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004210456383.png)

 上述轨迹是我们使用 Adagrad 进行不断调整的结果，我们可以看到在某几个位置处，由于 $g$ 的减小，t 的线性增长开始超过梯度的累积，此时 $lr$ 会增大，导致上下震荡的情况发生，为了解决这一问题，提出了 Learning Rate Scheduling（学习率调度）

1. Learning Rate Decay: 由于越到后面我们距离目标的 critical point 越近，所以我们设计一个递减的函数给 $\eta$
2. warm up: 由于开始不确定方向，所以 $\eta$ 故意设置的小一点，之后再逐渐递增，达到一个临界点或一定时间时，再开始缓减

|                     Learning Rate Decay                      |                           Warm up                            |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004212920492.png" alt="image-20241004212920492" style="zoom:150%;" /> | <img src="https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004212915048.png" alt="image-20241004212915048" style="zoom:149%;" /> |



### 8.4.4 Final GB

再经过多重改进后，我们对梯度下降的 update 过程描述如下：
$$
\boldsymbol{\theta}_i^{\boldsymbol{t}+\boldsymbol{1}} \leftarrow \boldsymbol{\theta}_i^{\boldsymbol{t}}-\frac{\eta^t}{\sigma_i^t} \boldsymbol{m}_i^{\boldsymbol{t}}
$$

- $\boldsymbol{m}$: momentum, last momentum 结合 current gradient

  > [!warning]
  >
  > 这里 $m$ 的推进是考虑到了方向的

- $\boldsymbol{\sigma}$: root mean square of gradients

  > [!warning]
  >
  > 这里的 $\boldsymbol{\sigma}$ 仅仅只与梯度的数值有关



## 8.5 how to do classification

其实我们可以用 Regression 来做 Classification，最快想到的一种办法就是 regression 不是最后会输出一个 scalar 吗？我们求出这个 scalar 与目标之间的距离，离的近就归为相应的类别。

但是这样做不一定准确，尤其是当类与类之间完全无关时更是如此，在这种情况下，我们需要使用 **One-hot vector**（独热编码）表示 ：
$$
\hat{y} = 
\overset{\text{Class 1}}{
\begin{bmatrix} 
1 \\ 0 \\ 0 
\end{bmatrix}} 
\quad \text{or} \quad 
\overset{\text{Class 2}}{
\begin{bmatrix} 
0 \\ 1 \\ 0 
\end{bmatrix}} 
\quad \text{or} \quad 
\overset{\text{Class 3}}{
\begin{bmatrix} 
0 \\ 0 \\ 1 
\end{bmatrix}}
$$
将上述的 class 转换为 One-hot vector 之后，三个类之间就没有关系，并且两两之间距离相等。

在 Regression 中，我们输出都是一个 scalar，现在我们做分类任务，需要有多个输出，可以将*输出的值*与 *权重矩阵* 相乘

![image-20241004232452819](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004232452819.png)
$$
\begin{aligned}
& \boldsymbol{y}=\boldsymbol{b}^{\prime}+W^{\prime} \sigma(\boldsymbol{b}+W \boldsymbol{x}) \\
& \widehat{\boldsymbol{y}}\dashleftarrow  \dashrightarrow\boldsymbol{y}^{\prime}=\operatorname{softmax}(\boldsymbol{y})
\end{aligned}
$$

> [!warning]
>
> 在这里，$\hat{y}$ 代表真值，$y$ 代表预测值，$y^{\prime}$ 代表将预测值归一化后的处理结果



![image-20241004233459741](https://thinkbook16-blog-img.oss-cn-zhangjiakou.aliyuncs.com/img_for_typora/image-20241004233459741.png)

在这里，Softmax 作用：

1. 归一化
2. 差异化：大的更大，小的更小

至于最后计算 **Loss of Classification**，我们有如下两种计算方式：

1. Mean Square Error(MSE): $e=\sum_i\left(\widehat{\boldsymbol{y}}_i-\boldsymbol{y}_i^{\prime}\right)^2$
2. Cross-entropy: $e=-\sum_i \widehat{y}_i \ln y_i^{\prime}$

一般情况下，**我们都选 Cross-entropy 作为我们计算 loss 的方式**

> [!tip]
>
> 在 PyTorch 中，Softmax 和 Cross-entropy 是绑在一起的 



:heart_eyes_cat:特别提醒：**Minimize Cross-entropy 其实就是 maximize likelihood**（最大似然估计）

